{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS336 Assignment 1 (basics): Building a Transformer LM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 The Unicode Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x00'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0000\n"
     ]
    }
   ],
   "source": [
    "print(chr(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\x00'\n"
     ]
    }
   ],
   "source": [
    "print(chr(0).__repr__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a test\\x00string'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"this is a test\" + chr(0) + \"string\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a test\u0000string\n"
     ]
    }
   ],
   "source": [
    "print(\"this is a test\" + chr(0) + \"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\x00',\n",
       " '\\x01',\n",
       " '\\x02',\n",
       " '\\x03',\n",
       " '\\x04',\n",
       " '\\x05',\n",
       " '\\x06',\n",
       " '\\x07',\n",
       " '\\x08',\n",
       " '\\t',\n",
       " '\\n',\n",
       " '\\x0b',\n",
       " '\\x0c',\n",
       " '\\r',\n",
       " '\\x0e',\n",
       " '\\x0f',\n",
       " '\\x10',\n",
       " '\\x11',\n",
       " '\\x12',\n",
       " '\\x13',\n",
       " '\\x14',\n",
       " '\\x15',\n",
       " '\\x16',\n",
       " '\\x17',\n",
       " '\\x18',\n",
       " '\\x19',\n",
       " '\\x1a',\n",
       " '\\x1b',\n",
       " '\\x1c',\n",
       " '\\x1d',\n",
       " '\\x1e',\n",
       " '\\x1f',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " '\\x7f',\n",
       " '\\x80',\n",
       " '\\x81',\n",
       " '\\x82',\n",
       " '\\x83',\n",
       " '\\x84',\n",
       " '\\x85',\n",
       " '\\x86',\n",
       " '\\x87',\n",
       " '\\x88',\n",
       " '\\x89',\n",
       " '\\x8a',\n",
       " '\\x8b',\n",
       " '\\x8c',\n",
       " '\\x8d',\n",
       " '\\x8e',\n",
       " '\\x8f',\n",
       " '\\x90',\n",
       " '\\x91',\n",
       " '\\x92',\n",
       " '\\x93',\n",
       " '\\x94',\n",
       " '\\x95',\n",
       " '\\x96',\n",
       " '\\x97',\n",
       " '\\x98',\n",
       " '\\x99',\n",
       " '\\x9a',\n",
       " '\\x9b',\n",
       " '\\x9c',\n",
       " '\\x9d',\n",
       " '\\x9e',\n",
       " '\\x9f',\n",
       " '\\xa0',\n",
       " '¡',\n",
       " '¢',\n",
       " '£',\n",
       " '¤',\n",
       " '¥',\n",
       " '¦',\n",
       " '§',\n",
       " '¨',\n",
       " '©',\n",
       " 'ª',\n",
       " '«',\n",
       " '¬',\n",
       " '\\xad',\n",
       " '®',\n",
       " '¯',\n",
       " '°',\n",
       " '±',\n",
       " '²',\n",
       " '³',\n",
       " '´',\n",
       " 'µ',\n",
       " '¶',\n",
       " '·',\n",
       " '¸',\n",
       " '¹',\n",
       " 'º',\n",
       " '»',\n",
       " '¼',\n",
       " '½',\n",
       " '¾',\n",
       " '¿',\n",
       " 'À',\n",
       " 'Á',\n",
       " 'Â',\n",
       " 'Ã',\n",
       " 'Ä',\n",
       " 'Å',\n",
       " 'Æ',\n",
       " 'Ç',\n",
       " 'È',\n",
       " 'É',\n",
       " 'Ê',\n",
       " 'Ë',\n",
       " 'Ì',\n",
       " 'Í',\n",
       " 'Î',\n",
       " 'Ï',\n",
       " 'Ð',\n",
       " 'Ñ',\n",
       " 'Ò',\n",
       " 'Ó',\n",
       " 'Ô',\n",
       " 'Õ',\n",
       " 'Ö',\n",
       " '×',\n",
       " 'Ø',\n",
       " 'Ù',\n",
       " 'Ú',\n",
       " 'Û',\n",
       " 'Ü',\n",
       " 'Ý',\n",
       " 'Þ',\n",
       " 'ß',\n",
       " 'à',\n",
       " 'á',\n",
       " 'â',\n",
       " 'ã',\n",
       " 'ä',\n",
       " 'å',\n",
       " 'æ',\n",
       " 'ç',\n",
       " 'è',\n",
       " 'é',\n",
       " 'ê',\n",
       " 'ë',\n",
       " 'ì',\n",
       " 'í',\n",
       " 'î',\n",
       " 'ï',\n",
       " 'ð',\n",
       " 'ñ',\n",
       " 'ò',\n",
       " 'ó',\n",
       " 'ô',\n",
       " 'õ',\n",
       " 'ö',\n",
       " '÷',\n",
       " 'ø',\n",
       " 'ù',\n",
       " 'ú',\n",
       " 'û',\n",
       " 'ü',\n",
       " 'ý',\n",
       " 'þ',\n",
       " 'ÿ']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[chr(i) for i in range(256)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Unicode Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'hello! \\xe3\\x81\\x93\\xe3\\x82\\x93\\xe3\\x81\\xab\\xe3\\x81\\xa1\\xe3\\x81\\xaf!'\n",
      "<class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "test_string = \"hello! こんにちは!\"\n",
    "utf8_encoded = test_string.encode(\"utf-8\")\n",
    "print(utf8_encoded)\n",
    "print(type(utf8_encoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[104, 101, 108, 108, 111, 33, 32, 227, 129, 147, 227, 130, 147, 227, 129, 171, 227, 129, 161, 227, 129, 175, 33]\n",
      "13\n",
      "23\n",
      "hello! こんにちは!\n"
     ]
    }
   ],
   "source": [
    "# Get the byte values for the encoded string (integers from 0 to 255).\n",
    "print(list(utf8_encoded))\n",
    "# One byte does not necessarily correspond to one Unicode character!\n",
    "print(len(test_string))\n",
    "print(len(utf8_encoded))\n",
    "print(utf8_encoded.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xff\\xfeh\\x00e\\x00l\\x00l\\x00o\\x00!\\x00 \\x00S0\\x930k0a0o0!\\x00'\n",
      "<class 'bytes'>\n",
      "[255, 254, 104, 0, 101, 0, 108, 0, 108, 0, 111, 0, 33, 0, 32, 0, 83, 48, 147, 48, 107, 48, 97, 48, 111, 48, 33, 0]\n",
      "13\n",
      "28\n",
      "hello! こんにちは!\n"
     ]
    }
   ],
   "source": [
    "utf16_encoded = test_string.encode(\"utf-16\")\n",
    "print(utf16_encoded)\n",
    "print(type(utf16_encoded))\n",
    "# Get the byte values for the encoded string (integers from 0 to 255).\n",
    "print(list(utf16_encoded))\n",
    "# One byte does not necessarily correspond to one Unicode character!\n",
    "print(len(test_string))\n",
    "print(len(utf16_encoded))\n",
    "print(utf16_encoded.decode(\"utf-16\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xff\\xfe\\x00\\x00h\\x00\\x00\\x00e\\x00\\x00\\x00l\\x00\\x00\\x00l\\x00\\x00\\x00o\\x00\\x00\\x00!\\x00\\x00\\x00 \\x00\\x00\\x00S0\\x00\\x00\\x930\\x00\\x00k0\\x00\\x00a0\\x00\\x00o0\\x00\\x00!\\x00\\x00\\x00'\n",
      "<class 'bytes'>\n",
      "[255, 254, 0, 0, 104, 0, 0, 0, 101, 0, 0, 0, 108, 0, 0, 0, 108, 0, 0, 0, 111, 0, 0, 0, 33, 0, 0, 0, 32, 0, 0, 0, 83, 48, 0, 0, 147, 48, 0, 0, 107, 48, 0, 0, 97, 48, 0, 0, 111, 48, 0, 0, 33, 0, 0, 0]\n",
      "13\n",
      "56\n",
      "hello! こんにちは!\n"
     ]
    }
   ],
   "source": [
    "utf32_encoded = test_string.encode(\"utf-32\")\n",
    "print(utf32_encoded)\n",
    "print(type(utf32_encoded))\n",
    "# Get the byte values for the encoded string (integers from 0 to 255).\n",
    "print(list(utf32_encoded))\n",
    "# One byte does not necessarily correspond to one Unicode character!\n",
    "print(len(test_string))\n",
    "print(len(utf32_encoded))\n",
    "print(utf32_encoded.decode(\"utf-32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xe3 in position 0: unexpected end of data",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode_utf8_bytes_to_str_wrong\u001b[39m(bytestring: \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join([\u001b[38;5;28mbytes\u001b[39m([b]).decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m bytestring])\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mdecode_utf8_bytes_to_str_wrong\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhello こんにちは\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mdecode_utf8_bytes_to_str_wrong\u001b[39m\u001b[34m(bytestring)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode_utf8_bytes_to_str_wrong\u001b[39m(bytestring: \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join([\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m bytestring])\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'utf-8' codec can't decode byte 0xe3 in position 0: unexpected end of data"
     ]
    }
   ],
   "source": [
    "def decode_utf8_bytes_to_str_wrong(bytestring: bytes):\n",
    "    return \"\".join([bytes([b]).decode(\"utf-8\") for b in bytestring])\n",
    "\n",
    "\n",
    "decode_utf8_bytes_to_str_wrong(\"hello こんにちは\".encode(\"utf-8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xe3\\x81\\x93'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"こ\".encode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12371"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord(\"こ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'こ'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(12371)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \\xe3 = (14 × 16¹) + (3 × 16⁰) = 224 + 3 = 227\n",
    "# Because it is hexadecimal (16). We multiply each value by 16 raised to the power of the position starting from 0 on the right.\n",
    "(14 * 16**1) + (3 * (16**0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[227, 129, 147]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[b for b in \"こ\".encode(\"utf-8\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[104, 105]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[b for b in \"hi\".encode(\"utf-8\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode bytes in position 0-1: unexpected end of data",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m227\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m129\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'utf-8' codec can't decode bytes in position 0-1: unexpected end of data"
     ]
    }
   ],
   "source": [
    "bytes([227, 129]).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes([104, 105]).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 BPE Tokenizer Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "from cs336_basics.bpe import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['some', ' text', ' that', ' i', \"'ll\", ' pre', '-', 'tokenize']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAT = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    "re.findall(PAT, \"some text that i'll pre-tokenize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['low',\n",
       " 'low',\n",
       " 'low',\n",
       " 'low',\n",
       " 'low',\n",
       " 'lower',\n",
       " 'lower',\n",
       " 'widest',\n",
       " 'widest',\n",
       " 'widest',\n",
       " 'newest',\n",
       " 'newest',\n",
       " 'newest',\n",
       " 'newest',\n",
       " 'newest',\n",
       " 'newest']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = \"\"\"low low low low low lower lower widest widest widest newest newest newest newest newest newest\"\"\"\n",
    "\n",
    "vocab = {bytes([i]): i for i in range(256)}\n",
    "vocab[\"<|endoftext|>\".encode(\"utf-8\")] = 257\n",
    "pre_tokenized = corpus.split(\" \")\n",
    "pre_tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Experimenting with BPE Tokenizer Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs336_basics.bpe import *\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {(b'l', b'o', b'w'): 1,\n",
       "             (b' ', b'l', b'o', b'w'): 4,\n",
       "             (b' ', b'l', b'o', b'w', b'e', b'r'): 2,\n",
       "             (b' ', b'w', b'i', b'd', b'e', b's', b't'): 3,\n",
       "             (b' ', b'n', b'e', b'w', b'e', b's', b't'): 6})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = \"\"\"low low low low low lower lower widest widest widest newest newest newest newest newest newest\"\"\"\n",
    "pre_tokenizer = Pretokenizer()\n",
    "symbol_seq_counts = pre_tokenizer(corpus)\n",
    "symbol_seq_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_trainer = BPETrainer()\n",
    "\n",
    "# Init state for efficient incremental merging\n",
    "bpe_trainer.symbol_seq_counts = symbol_seq_counts\n",
    "bpe_trainer.bytepair2seqs = bpe_trainer._bytepairs_to_symbol_seqs()\n",
    "bpe_trainer.seq2bytepair = bpe_trainer._symbol_seqs_to_bytepairs()\n",
    "bpe_trainer.bytepair_counts = bpe_trainer._to_bytepair_counts(bpe_trainer.symbol_seq_counts)\n",
    "bpe_trainer.heap = [HeapItem(-freq, bp) for bp, freq in bpe_trainer.bytepair_counts.items()]\n",
    "heapq.heapify(bpe_trainer.heap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {(b'l', b'o'): 7,\n",
       "             (b'o', b'w'): 7,\n",
       "             (b' ', b'l'): 6,\n",
       "             (b'w', b'e'): 8,\n",
       "             (b'e', b'r'): 2,\n",
       "             (b' ', b'w'): 3,\n",
       "             (b'w', b'i'): 3,\n",
       "             (b'i', b'd'): 3,\n",
       "             (b'd', b'e'): 3,\n",
       "             (b'e', b's'): 9,\n",
       "             (b's', b't'): 9,\n",
       "             (b' ', b'n'): 6,\n",
       "             (b'n', b'e'): 6,\n",
       "             (b'e', b'w'): 6})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe_trainer.bytepair_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HeapItem(neg_freq=-9, pair=(b's', b't')),\n",
       " HeapItem(neg_freq=-9, pair=(b'e', b's')),\n",
       " HeapItem(neg_freq=-6, pair=(b'n', b'e')),\n",
       " HeapItem(neg_freq=-8, pair=(b'w', b'e')),\n",
       " HeapItem(neg_freq=-7, pair=(b'o', b'w')),\n",
       " HeapItem(neg_freq=-6, pair=(b' ', b'n')),\n",
       " HeapItem(neg_freq=-6, pair=(b'e', b'w')),\n",
       " HeapItem(neg_freq=-3, pair=(b'i', b'd')),\n",
       " HeapItem(neg_freq=-3, pair=(b'd', b'e')),\n",
       " HeapItem(neg_freq=-7, pair=(b'l', b'o')),\n",
       " HeapItem(neg_freq=-2, pair=(b'e', b'r')),\n",
       " HeapItem(neg_freq=-6, pair=(b' ', b'l')),\n",
       " HeapItem(neg_freq=-3, pair=(b' ', b'w')),\n",
       " HeapItem(neg_freq=-3, pair=(b'w', b'i'))]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe_trainer.heap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b's', b't')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe_trainer._bp_merging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {0: b\" \", 1: b\"a\", 2: b\"c\", 3: b\"e\", 4: b\"h\", 5: b\"t\", 6: b\"th\", 7: b\" c\", 8: b\" a\", 9: b\"the\", 10: b\"at\"}\n",
    "merges = [(b\"t\", b\"h\"), (b\" \", b\"c\"), (b\" \", \"a\"), (b\"th\", b\"e\"), (b\" a\", b\"t\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(b't', b'h', b'e'), (b'c', b'a', b't'), (b'a', b't', b'e')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"the cat ate\"\n",
    "pre_tokenised = text.split()\n",
    "\n",
    "\n",
    "def string2tuple_of_bytes(s: str) -> tuple[bytes]:\n",
    "    return tuple(bytes([i]) for i in s.encode(\"utf-8\"))\n",
    "\n",
    "\n",
    "pre_tokenised = [string2tuple_of_bytes(i) for i in pre_tokenised]\n",
    "pre_tokenised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(b't', b'h')\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(pw)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pw == m:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     token = \u001b[43mtoken\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(pw, m)\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'tuple' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "from itertools import pairwise\n",
    "\n",
    "\n",
    "for token in pre_tokenised:\n",
    "    for m in merges:\n",
    "        for pw in pairwise(token):\n",
    "            print(pw)\n",
    "            if pw == m:\n",
    "                token = token.replace(pw, m)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from typing import Iterable\n",
    "\n",
    "\n",
    "class Tokenizer:\n",
    "    def __init__(\n",
    "        self, vocab: dict[int, bytes], merges: list[tuple[bytes, bytes]], special_tokens: list[str] | None = None\n",
    "    ):\n",
    "        self.vocab = vocab\n",
    "        self.merges = merges\n",
    "\n",
    "    def from_files(cls, vocab_filepath, merges_filepath, special_tokens=None):\n",
    "        vocab = pickle.load(open(vocab_filepath, \"rb\"))\n",
    "        merges = pickle.load(open(merges_filepath, \"rb\"))\n",
    "        return cls(vocab, merges, special_tokens)\n",
    "\n",
    "    def encode(self, text: str) -> list[int]:\n",
    "        pass\n",
    "\n",
    "    def encode_iterable(self, iterable: Iterable[str]) -> list[int]:\n",
    "        pass\n",
    "\n",
    "    def decode(self, ids: list[int]) -> str:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
